{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.0.1\n",
      "Apache Spark version:  3.0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0df3da6dc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('project',\n",
       " 'We are seeking a full-time AP Clerk to support our accounting team. Job descriptions: Timely process vendor invoices for multi-entities Weekly payment process and positive pay uploading Maintain accurate vendor wire templates and process wire payments Create/import inbound reports Credit card transaction reconciliations Travel expense / employee reimbursement report Investigate aging AP and reconcile AP balance with vendors’ statements of accounts Maintain Fixed Assets log Ad hoc projects and misc. tasks Education and skills requirements: Associate degree in Accounting or Finance or high school diploma Very organized and detail oriented Positive work attitude and multi-task Proficient in Microsoft Office especially Excel; ERP experience (NetSuite) is preferred but not required. Others: This position will be in person to the office. Job Type: Full-time Pay: $40')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"project\", \"Experienced Data Scientist with a demonstrated history of working in the information technology and services industry. Skilled in Python (Programming Language), SQL and Data Science. Strong engineering professional graduated from Tbilisi State University.\")\n",
    "('project','We are seeking a full-time AP Clerk to support our accounting team. Job descriptions: Timely process vendor invoices for multi-entities Weekly payment process and positive pay uploading Maintain accurate vendor wire templates and process wire payments Create/import inbound reports Credit card transaction reconciliations Travel expense / employee reimbursement report Investigate aging AP and reconcile AP balance with vendors’ statements of accounts Maintain Fixed Assets log Ad hoc projects and misc. tasks Education and skills requirements: Associate degree in Accounting or Finance or high school diploma Very organized and detail oriented Positive work attitude and multi-task Proficient in Microsoft Office especially Excel; ERP experience (NetSuite) is preferred but not required. Others: This position will be in person to the office. Job Type: Full-time Pay: $40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(title='project', description='designs and builds computer programs that power mobile devices, desktop computers, and even cars. They not only identify user needs but also create new applications for any given market while making improvements based on feedback from users.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for testing\n",
    "columns = [\"title\",\"description\"]\n",
    "data = [('project','designs and builds computer programs that power mobile devices, desktop computers, and even cars. They not only identify user needs but also create new applications for any given market while making improvements based on feedback from users.')]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "input_data = spark.createDataFrame(data).toDF(*columns)\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titleDF = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"data/training_all_data.csv\", sep=r'@')\n",
    "\n",
    "huge_data = titleDF.union(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleDF.select('description').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string, description: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleDF.filter(titleDF.title.isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(title='softwar develop', count=4808), Row(title='technician', count=1565)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "titleDF.groupBy(\"title\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.6 ms, sys: 25.3 ms, total: 99.9 ms\n",
      "Wall time: 27.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17479"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"description\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "      \n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"title\", outputCol = \"label\")\n",
    "\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "            countVectors,\n",
    "            label_stringIdx])\n",
    "\n",
    "nlp_model = nlp_pipeline.fit(huge_data)\n",
    "processed = nlp_model.transform(titleDF)\n",
    "\n",
    "processed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                       description|                                    token_features|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|We are looking for a dependable Pharmacy Techni...|[look, depend, pharmaci, technician, process, f...|\n",
      "|\"Required License Type: CDL-B Required License ...|[requir, licens, typ, cdlb, requir, licens, end...|\n",
      "|Working at the Y, you have the opportunity to s...|[work, y, opportun, strengthen, commun, chang, ...|\n",
      "| Multifaceted, engagingÂ & challenging role.Â  ...|[multifacet, engagingâ, challeng, roleâ, conven...|\n",
      "|\"The High Companies began our work in 1931 with...|[high, compani, began, work, firmli, establish,...|\n",
      "|JobID: 20564 Position Type: APS Recruitment/Lic...|[jobid, posit, typ, ap, recruitmentlicens, supp...|\n",
      "|Summary To provide coverage for patient care fo...|[summari, provid, coverag, patient, care, emerg...|\n",
      "|Waverly Rehabilitation And Healthcare Center 45...|[waverli, rehabilit, healthcar, center, e, main...|\n",
      "|With minimum supervision administer radiation t...|[minimum, supervis, administ, radiat, therapi, ...|\n",
      "|Overview: Adams Street Partners (“Adams Street”...|[overview, adam, street, partner, adam, street,...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Leads and...|[posit, summari, youll, lead, develop, team, ef...|\n",
      "|Position Summary... What you'll do... Completes...|[posit, summari, youll, complet, work, assign, ...|\n",
      "|For more information on this C++ Engineer oppor...|[inform, c++, engin, opportun, support, fleet, ...|\n",
      "|For more information on this C++ Engineer oppor...|[inform, c++, engin, opportun, support, fleet, ...|\n",
      "|Read what people are saying about working here....|[read, peopl, saye, work, job, summari, guidanc...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed.select('description','token_features').show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|         description|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|We are looking fo...|(10000,[0,1,3,4,6...|  1.0|\n",
      "|\"Required License...|(10000,[0,1,3,4,5...| 11.0|\n",
      "|Working at the Y,...|(10000,[0,1,2,3,4...| 13.0|\n",
      "| Multifaceted, en...|(10000,[0,1,2,5,8...|  9.0|\n",
      "|\"The High Compani...|(10000,[0,1,3,4,5...|  9.0|\n",
      "|JobID: 20564 Posi...|(10000,[0,1,2,3,8...|  5.0|\n",
      "|Summary To provid...|(10000,[1,3,4,9,1...| 16.0|\n",
      "|Waverly Rehabilit...|(10000,[5,9,11,14...|  2.0|\n",
      "|With minimum supe...|(10000,[4,12,13,1...| 14.0|\n",
      "|Overview: Adams S...|(10000,[0,1,2,3,4...| 18.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...| 11.0|\n",
      "|Position Summary....|(10000,[0,1,2,3,4...|  1.0|\n",
      "|For more informat...|(10000,[1,2,3,4,5...|  0.0|\n",
      "|For more informat...|(10000,[1,2,3,4,5...|  0.0|\n",
      "|Read what people ...|(10000,[0,2,3,5,6...|  0.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed.select('description','features','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 13992\n",
      "Test Dataset Count: 3487\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = processed.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- normalized: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- cleanTokens: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- stem: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token_features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------+------------------------------+-----+----------+\n",
      "|                   description|          title|                   probability|label|prediction|\n",
      "+------------------------------+---------------+------------------------------+-----+----------+\n",
      "|\"Read what people are sayin...|softwar develop|[0.9998808347099905,1.58860...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9994606117093139,5.57152...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9994073934131825,1.99954...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9992017177489978,8.83071...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9989919517723896,2.05479...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9989147670347271,7.17656...|  0.0|       0.0|\n",
      "|  Senior Software Developer...|softwar develop|[0.9989013461534338,2.80340...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9986347473891423,8.28768...|  0.0|       0.0|\n",
      "|Read what people are saying...|softwar develop|[0.9986219745932549,2.83013...|  0.0|       0.0|\n",
      "|Overview  Geocent offers ex...|softwar develop|[0.9981850153858214,6.56370...|  0.0|       0.0|\n",
      "+------------------------------+---------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10000, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"description\",\"title\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7468835433202499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_true = predictions.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     1255\n",
       "1.0      383\n",
       "4.0      292\n",
       "2.0      272\n",
       "3.0      251\n",
       "5.0      206\n",
       "6.0      138\n",
       "7.0      121\n",
       "10.0      81\n",
       "8.0       79\n",
       "13.0      59\n",
       "12.0      44\n",
       "14.0      40\n",
       "11.0      34\n",
       "9.0       33\n",
       "15.0      30\n",
       "21.0      26\n",
       "16.0      22\n",
       "23.0      18\n",
       "18.0      17\n",
       "24.0      14\n",
       "20.0      13\n",
       "22.0      10\n",
       "32.0       8\n",
       "19.0       8\n",
       "27.0       7\n",
       "29.0       6\n",
       "17.0       5\n",
       "26.0       4\n",
       "25.0       4\n",
       "28.0       3\n",
       "30.0       3\n",
       "31.0       1\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[940,   3,   0, ...,   0,   0,   0],\n",
       "       [ 20, 272,   5, ...,   0,   0,   0],\n",
       "       [  2,   0, 216, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(list(y_true.label.astype(int)), list(y_pred.prediction.astype(int)))\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string, description: string, document: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, token: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, normalized: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, cleanTokens: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, stem: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, token_features: array<string>, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.98      0.85       955\n",
      "         1.0       0.71      0.84      0.77       322\n",
      "         2.0       0.79      0.95      0.87       227\n",
      "         3.0       0.70      0.78      0.74       226\n",
      "         4.0       0.70      0.89      0.79       230\n",
      "         5.0       0.87      0.91      0.89       196\n",
      "         6.0       0.89      0.91      0.90       135\n",
      "         7.0       0.74      0.69      0.72       130\n",
      "         8.0       0.90      0.60      0.72       118\n",
      "         9.0       0.82      0.31      0.45        88\n",
      "        10.0       0.94      0.78      0.85        97\n",
      "        11.0       0.91      0.46      0.61        68\n",
      "        12.0       0.77      0.49      0.60        69\n",
      "        13.0       0.85      0.74      0.79        68\n",
      "        14.0       0.85      0.58      0.69        59\n",
      "        15.0       0.97      0.57      0.72        51\n",
      "        16.0       0.95      0.60      0.74        35\n",
      "        17.0       0.40      0.06      0.11        31\n",
      "        18.0       0.94      0.47      0.63        34\n",
      "        19.0       0.62      0.14      0.23        36\n",
      "        20.0       0.62      0.28      0.38        29\n",
      "        21.0       0.92      0.80      0.86        30\n",
      "        22.0       0.70      0.24      0.36        29\n",
      "        23.0       1.00      0.69      0.82        26\n",
      "        24.0       0.79      0.42      0.55        26\n",
      "        25.0       0.75      0.14      0.24        21\n",
      "        26.0       0.50      0.10      0.16        21\n",
      "        27.0       1.00      0.33      0.50        21\n",
      "        28.0       0.67      0.10      0.17        20\n",
      "        29.0       1.00      0.25      0.40        24\n",
      "        30.0       1.00      0.13      0.23        23\n",
      "        31.0       1.00      0.08      0.14        13\n",
      "        32.0       0.88      0.50      0.64        14\n",
      "        33.0       0.00      0.00      0.00         7\n",
      "        34.0       0.00      0.00      0.00         4\n",
      "        35.0       0.00      0.00      0.00         2\n",
      "        38.0       0.00      0.00      0.00         1\n",
      "        39.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77      3487\n",
      "   macro avg       0.71      0.44      0.50      3487\n",
      "weighted avg       0.78      0.77      0.75      3487\n",
      "\n",
      "0.773157441927158\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors,Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|label|\n",
      "+--------------------+-----+\n",
      "|softwar develop i...| 29.0|\n",
      "|             plumber| 34.0|\n",
      "|    field technician| 19.0|\n",
      "|       product owner| 24.0|\n",
      "|        receptionist|  4.0|\n",
      "|             cleaner| 37.0|\n",
      "|       staff auntant| 39.0|\n",
      "|             teacher|  5.0|\n",
      "|       it specialist| 12.0|\n",
      "|           physician| 16.0|\n",
      "|softwar develop e...| 33.0|\n",
      "|             trainer| 22.0|\n",
      "|            attorney| 35.0|\n",
      "|     softwar develop|  0.0|\n",
      "|       custom servic|  7.0|\n",
      "|  softwar develop ii| 20.0|\n",
      "|               offic|  9.0|\n",
      "|               coach| 11.0|\n",
      "|       night auditor| 32.0|\n",
      "|       social worker| 15.0|\n",
      "|       human resourc| 13.0|\n",
      "|          pharmacist| 36.0|\n",
      "|full stack softwa...| 28.0|\n",
      "|             of nurs| 23.0|\n",
      "|            warehous| 10.0|\n",
      "|       er technician| 31.0|\n",
      "|            dishwash| 38.0|\n",
      "|           architect|  8.0|\n",
      "| net softwar develop| 30.0|\n",
      "|  support technician| 26.0|\n",
      "|            assessor| 27.0|\n",
      "|               clerk|  3.0|\n",
      "|              writer| 18.0|\n",
      "|             cashier|  6.0|\n",
      "|           therapist|  2.0|\n",
      "|              servic| 25.0|\n",
      "|          technician|  1.0|\n",
      "|      support worker| 21.0|\n",
      "|       softwar engin| 17.0|\n",
      "|        technologist| 14.0|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.select('title','label').distinct().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfFromRDD2 = spark.createDataFrame(data).toDF(*columns)\n",
    "test = nlp_model.transform(dfFromRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = Matrix(rdd, 2)\n",
    "lrModel.predict(test.head().features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
